\documentclass[12pt,preprintnumbers,amsmath,amssymb,titlepage]{report}
\usepackage{amsmath,amsthm,amssymb,dcolumn,epsf,ulem,relsize,graphicx}
\setkeys{Gin}{width=8.6cm,keepaspectratio}
\graphicspath{{pngs/}}
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage[]{units}
\usepackage{subfig}
\usepackage{floatrow}
\floatsetup[table]{capposition=bottom} 
\captionsetup{font={small,rm}}
\captionsetup{belowskip=0pt}
\usepackage{wrapfig}
\usepackage{caption}
\usepackage{array}
\usepackage{booktabs}
\usepackage[margin = 1in]{geometry}
\usepackage{siunitx}
\sisetup{output-exponent-marker=\textsc{e}}
\usepackage{setspace}
\onehalfspace
\setlength{\parindent}{0em}
\setlength{\parskip}{.5em}
\allowdisplaybreaks[2]
\newcommand{\refe}[1]{Eq. (\ref{#1})}


\begin{document}

\title{Modeling the Lorenz Attractor with SINDY}
\author{Lia Gianfortone}
\date{December 2017}

\maketitle


\section*{Abstract}

\section*{Introduction}

System identification techniques that use measured data to recover a system's governing equations are useful for a wide range of applications. The system-identification algorithm proposed in [paper] involves sparse identifications of nonlinear dynamical systems (SINDy). The algorithm relies on the assumption that dynamics of the system depend on only a few linear and nonlinear terms which will guarantee the sparsity of the solution. 


\section*{SINDY Algorithm}
The algorithm is effective under the assumption that the systems studied with SINDy have dynamics that are depend by only a few terms and are thus sparse in a high-dimensional, nonlinear function space. 

We consider systems of the form 
\begin{equation}
\frac{d}{dt}\bm{x}(t) = \bm{f}(\bm{x}(t))
\end{equation}
where $\bm{x}(t) \in \mathbb{R}^n$ is the state of the system at time $t$ and $\bm{f}$ consists of the governing equations of the system. 

To compute the active nonlinear terms in the dynamics, we construct the system 
\begin{equation} \label{eqn:main}
	\bm{\dot{X}} = \bm{\Theta}(\bm{X})\bm{\Xi}
\end{equation}
where $\bm{X}$ and $\bm{\dot{X}}$ are data matrices containing the samples of the state and its derivative at times $t_1, t_2, \cdots, t_m$ arranged as follows
\begin{equation*}
	\bm{X} = \begin{bmatrix} 
				\bm{x}^T(t_1) \\ \bm{x}^T(t_2) \\ \vdots \\ \bm{x}^T(t_m)
			\end{bmatrix}
		   = \begin{bmatrix}
		   		x_1(t_1) & x_2(t_1) & \cdots & x_n(t_1) \\
		   		x_1(t_2) & x_2(t_2) & \cdots & x_n(t_2) \\
		   		\vdots   & \vdots   & \ddots & \vdots   \\
		   		x_1(t_m) & x_2(t_m) & \cdots & x_n(t_m) 
	   		\end{bmatrix}
\end{equation*}

\begin{equation*}
	\bm{\dot{X}} = \begin{bmatrix} 
				\bm{\dot{x}}^T(t_1) \\ \bm{\dot{x}}^T(t_2) \\ \vdots \\ \bm{\dot{x}}^T(t_m)
			\end{bmatrix}
		   = \begin{bmatrix}
		   		\dot{x}_1(t_1) & \dot{x}_2(t_1) & \cdots & \dot{x}_n(t_1) \\
		   		\dot{x}_1(t_2) & \dot{x}_2(t_2) & \cdots & \dot{x}_n(t_2) \\
		   		\vdots    	   & \vdots   		& \ddots & \vdots  \\
		   		\dot{x}_1(t_m) & \dot{x}_2(t_m) & \cdots & \dot{x}_n(t_m)
	   		\end{bmatrix}.
\end{equation*}
The state data are input to the library of candidate functions, $\bm{\Theta}(\bm{X})$, which consist of constant, polynomial, and trigonometric terms that are chosen based on hypotheses (based on symmetry, physics, etc.) about the system dynamics. [[More about choosing functions]]. The candidate functions are arranged in a matrix 
\begin{equation}
	\bm{\Theta}(\bm{X}) = 
	\begin{bmatrix}
		\mid & \mid 	& \mid 	 		&        & \mid	  		& \mid 		   &  		\\
		1	 & \bm{X}   & \bm{X}^{P_2}  & \cdots & \sin(\bm{X}) & \cos(\bm{X}) & \cdots \\
		\mid & \mid 	& \mid 	 		&        & \mid	  		& \mid  	   &
	\end{bmatrix}
\end{equation}
where polynomial cross-terms of degree $i$ are denoted $\bm{X}^{P_i}$. For example, $\bm{X}^{P_i}$ contains quadratic nonlinearities in the state $\bm{x}$,
\begin{equation*}
	\bm{X}^{P_2} = 
		\begin{bmatrix}
			x_1^2(t_1)	&	x_1(t_1)x_2(t_1) & \cdots & x_2^2(t_1) & \cdots & x_n^2(t_1) \\
			x_1^2(t_2)	&	x_1(t_2)x_2(t_2) & \cdots & x_2^2(t_2) & \cdots & x_n^2(t_2) \\
			\vdots		&	\vdots		     & \ddots & \vdots	   & \ddots & \vdots	 \\
			x_1^2(t_m)	&	x_1(t_m)x_2(t_m) & \cdots & x_2^2(t_m) & \cdots & x_n^2(t_m) \\
		\end{bmatrix}.
\end{equation*}
The final term in \refe{eqn:main}, $\bm{\Xi} = [\bm{\xi}_1 \bm{\xi}_2 \cdots \bm{\xi}_n]$ is the desired sparse matrix of coefficients that determine which of the candidate functions in $\bm{\Theta}(\bm{X})$ are active in the system. Solving for these coefficients requires a distinct optimization of each vector, 
\begin{equation} \label{eqn:vector}
	\bm{\dot{x}} = \bm{f}(\bm{x}) = \bm{\Xi}^T(\bm{\Theta}(\bm{x}^T))^T.
\end{equation}

Algorithms to perform the desired sparse regression of \refe{eqn:vector} include LASSO, which uses the $L_1$-norm to ensure sparsity, and the sequential least squares method. In this study, sequential least squares was the method of choice.



% \section*{Vortex Shedding}

\section*{SINDyC Algorithm}



\section*{Lorenz Attractor}

\subsection*{Theory}

\subsection*{Results}



\section{Further Study}

\section*{Conclusion}

\section*{Bibliography}

\appendix{Code}

\appendix{Figures}



\end{document}